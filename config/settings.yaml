# Default runtime configuration for My AI Agent
# These values are loaded by a Pydantic `Settings` class and can be
# overridden by environment variables or CLI parameters.

llm:
  provider: openai            # "openai", "azure", "cohere", etc.
  model_name: gpt-4o-mini     # Default chat model
  temperature: 0.0            # Deterministic answers
  max_tokens: 4096            # Hard ceiling for responses

# Search Configuration
search:
  provider: "serpapi"
  enabled: true

# Memory Configuration
memory:
  type: "conversation_buffer"
  max_token_limit: 2000
  window_size: 8              # How many turns to keep in short-term memory

# Agent Configuration
agent:
  type: "chat_conversational_react_description"
  verbose: true

# Embedding Configuration
embeddings:
  provider: openai
  model_name: text-embedding-3-small
  chunk_size: 1000            # Characters per chunk

# Vector Store Configuration
vector_store:
  type: chroma                # "chroma", "faiss", "redis", etc.
  persist_directory: ./chroma_db

# Enable/disable built-in tools
tools:
  enabled:
    - search
    - calculator
